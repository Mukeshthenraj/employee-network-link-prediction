# -*- coding: utf-8 -*-
"""employee-network-link-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1II4jQSyXWuEoIoRQVtoEWuS_Bst5iWzB

# Assignment 4
"""

import networkx as nx
import pandas as pd
import numpy as np
import pickle

"""---

## Part 1 - Random Graph Identification

For the first part of this assignment you will analyze randomly generated graphs and determine which algorithm created them.
"""

G1 = nx.read_gpickle("assets/A4_P1_G1")
G2 = nx.read_gpickle("assets/A4_P1_G2")
G3 = nx.read_gpickle("assets/A4_P1_G3")
G4 = nx.read_gpickle("assets/A4_P1_G4")
G5 = nx.read_gpickle("assets/A4_P1_G5")
P1_Graphs = [G1, G2, G3, G4, G5]

"""<br>
`P1_Graphs` is a list containing 5 networkx graphs. Each of these graphs were generated by one of three possible algorithms:
* Preferential Attachment (`'PA'`)
* Small World with low probability of rewiring (`'SW_L'`)
* Small World with high probability of rewiring (`'SW_H'`)

Anaylze each of the 5 graphs using any methodology and determine which of the three algorithms generated each graph.

*The `graph_identification` function should return a list of length 5 where each element in the list is either `'PA'`, `'SW_L'`, or `'SW_H'`.*
"""

def graph_identification():
    # Based on clustering, path length, and degree stats:
    # G1 = PA, G2 = SW_L, G3 = SW_L, G4 = PA, G5 = SW_H
    return ['PA', 'SW_L', 'SW_L', 'PA', 'SW_H']

ans_one = graph_identification()
assert type(ans_one) == list, "You must return a list"

ans_one = graph_identification()
print(ans_one)

"""---

## Part 2 - Company Emails

For the second part of this assignment you will be working with a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.

The network also contains the node attributes `Department` and `ManagmentSalary`.

`Department` indicates the department in the company which the person belongs to, and `ManagmentSalary` indicates whether that person is receiving a managment position salary.
"""

G = pickle.load(open('assets/email_prediction_NEW.txt', 'rb'))

print(f"Graph with {len(nx.nodes(G))} nodes and {len(nx.edges(G))} edges")

"""### Part 2A - Salary Prediction

Using network `G`, identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a managment position salary.

To accomplish this, you will need to create a matrix of node features of your choice using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a managment salary for nodes where `ManagementSalary` is missing.



Your predictions will need to be given as the probability that the corresponding employee is receiving a managment position salary.

The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).

Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will recieve full points.

Using your trained classifier, return a Pandas series of length 252 with the data being the probability of receiving managment salary, and the index being the node id.

    Example:
    
        1       1.0
        2       0.0
        5       0.8
        8       1.0
            ...
        996     0.7
        1000    0.5
        1001    0.0
        Length: 252, dtype: float64
"""

list(G.nodes(data=True))[:5] # print the first 5 nodes

def salary_predictions():
    from sklearn.ensemble import RandomForestClassifier
    import pandas as pd
    import networkx as nx

    # Get all node features
    degree = dict(nx.degree(G))
    clustering = nx.clustering(G)
    betweenness = nx.betweenness_centrality(G)
    closeness = nx.closeness_centrality(G)
    pagerank = nx.pagerank(G)

    # Combine features into a DataFrame
    df = pd.DataFrame({
        'degree': pd.Series(degree),
        'clustering': pd.Series(clustering),
        'betweenness': pd.Series(betweenness),
        'closeness': pd.Series(closeness),
        'pagerank': pd.Series(pagerank),
        'ManagementSalary': pd.Series(nx.get_node_attributes(G, 'ManagementSalary'))
    })

    # Split into train and predict sets
    train_df = df[~df['ManagementSalary'].isnull()]
    test_df = df[df['ManagementSalary'].isnull()]

    # Features and labels
    X_train = train_df.drop('ManagementSalary', axis=1)
    y_train = train_df['ManagementSalary']
    X_test = test_df.drop('ManagementSalary', axis=1)

    # Train the model
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)

    # Predict probabilities for the test set (management salary = 1.0)
    preds = model.predict_proba(X_test)[:, 1]

    # Return as a Pandas Series
    return pd.Series(preds, index=X_test.index)

ans_salary_preds = salary_predictions()
assert type(ans_salary_preds) == pd.core.series.Series, "You must return a Pandas series"
assert len(ans_salary_preds) == 252, "The series must be of length 252"

print(ans_salary_preds.head())

import matplotlib.pyplot as plt
ans_salary_preds.hist(bins=20)
plt.title("Predicted Management Probabilities")

"""### Part 2B - New Connections Prediction

For the last part of this assignment, you will predict future connections between employees of the network. The future connections information has been loaded into the variable `future_connections`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection.
"""

future_connections = pd.read_csv('assets/Future_Connections.csv', index_col=0, converters={0: eval})
future_connections.head(10)

"""Using network `G` and `future_connections`, identify the edges in `future_connections` with missing values and predict whether or not these edges will have a future connection.

To accomplish this, you will need to:      
1. Create a matrix of features of your choice for the edges found in `future_connections` using Networkx     
2. Train a sklearn classifier on those edges in `future_connections` that have `Future Connection` data     
3. Predict a probability of the edge being a future connection for those edges in `future_connections` where `Future Connection` is missing.



Your predictions will need to be given as the probability of the corresponding edge being a future connection.

The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).

Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will recieve full points.

Using your trained classifier, return a series of length 122112 with the data being the probability of the edge being a future connection, and the index being the edge as represented by a tuple of nodes.

    Example:
    
        (107, 348)    0.35
        (542, 751)    0.40
        (20, 426)     0.55
        (50, 989)     0.35
                  ...
        (939, 940)    0.15
        (555, 905)    0.35
        (75, 101)     0.65
        Length: 122112, dtype: float64
"""

def new_connections_predictions():
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.ensemble import RandomForestClassifier

    import pandas as pd
    import networkx as nx

    # Load the future connections file
    future = future_connections.copy()

    # Initialize feature dictionary
    features = {}

    # Compute Jaccard Coefficient
    jc = nx.jaccard_coefficient(G, future.index)
    for u, v, val in jc:
        features[(u, v)] = {'jaccard': val}

    # Preferential Attachment
    pa = nx.preferential_attachment(G, future.index)
    for u, v, val in pa:
        features[(u, v)]['pa'] = val

    # Resource Allocation Index
    ra = nx.resource_allocation_index(G, future.index)
    for u, v, val in ra:
        features[(u, v)]['ra'] = val

    # Number of common neighbors
    for u, v in future.index:
        common = list(nx.common_neighbors(G, u, v))
        features[(u, v)]['common_neighbors'] = len(common)

    # Build DataFrame from features
    df_feat = pd.DataFrame.from_dict(features, orient='index')

    # Join target labels
    df_feat['target'] = future['Future Connection']

    # Split
    train_df = df_feat[~df_feat['target'].isnull()]
    test_df = df_feat[df_feat['target'].isnull()]

    # Train the model
    model = RandomForestClassifier(random_state=42)
    model.fit(train_df.drop('target', axis=1), train_df['target'])

    # Predict probabilities
    preds = model.predict_proba(test_df.drop('target', axis=1))[:, 1]

    # Return as a Pandas Series
    return pd.Series(preds, index=test_df.index)

ans_prob_preds = new_connections_predictions()
assert type(ans_prob_preds) == pd.core.series.Series, "You must return a Pandas series"
assert len(ans_prob_preds) == 122112, "The series must be of length 122112"

print(ans_prob_preds.head())

import matplotlib.pyplot as plt

# Draw the original graph
plt.figure(figsize=(10, 8))
pos = nx.spring_layout(G, seed=42)  # layout for consistent positioning

# Draw the existing graph in light gray
nx.draw_networkx(G, pos, node_size=50, edge_color='lightgray', with_labels=False)

# Highlight 50 predicted future edges with high probability (> 0.9)
high_prob = ans_prob_preds[ans_prob_preds > 0.9].sample(50, random_state=42)

# Draw those predicted future edges in red
nx.draw_networkx_edges(G, pos, edgelist=high_prob.index, edge_color='red')

plt.title("Graph G with Top Predicted Future Edges (> 0.9)")
plt.show()

ans_prob_preds.hist(bins=30, figsize=(8, 4))
plt.title("Distribution of Predicted Future Connection Probabilities")
plt.xlabel("Probability of Future Connection")
plt.ylabel("Number of Pairs")
plt.show()

import pandas as pd
import networkx as nx

# Copy of the future_connections data
future = future_connections.copy()

# Initialize an empty dictionary to store all features
features = {}

# Jaccard Coefficient
jc = nx.jaccard_coefficient(G, future.index)
for u, v, val in jc:
    features[(u, v)] = {'jaccard': val}

# Preferential Attachment
pa = nx.preferential_attachment(G, future.index)
for u, v, val in pa:
    features[(u, v)]['pa'] = val

# Resource Allocation Index
ra = nx.resource_allocation_index(G, future.index)
for u, v, val in ra:
    features[(u, v)]['ra'] = val

# Common Neighbors Count
for u, v in future.index:
    features[(u, v)]['common_neighbors'] = len(list(nx.common_neighbors(G, u, v)))

df_feat = pd.DataFrame.from_dict(features, orient='index')

# Add target column from the CSV file
df_feat['target'] = future_connections['Future Connection']

train_df = df_feat[~df_feat['target'].isnull()]  # has known 0 or 1
test_df = df_feat[df_feat['target'].isnull()]    # we must predict these

from sklearn.ensemble import RandomForestClassifier

X_train = train_df.drop('target', axis=1)
y_train = train_df['target']

model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

import matplotlib.pyplot as plt

importances = model.feature_importances_
features = X_train.columns

plt.figure(figsize=(6, 4))
plt.barh(features, importances)
plt.title("Feature Importance from Random Forest")
plt.xlabel("Importance Score")
plt.show()

